{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henrytsui/anaconda3/envs/IDS/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock(Dataset):\n",
    "    def __init__(self, df, news_max = 20) -> None:\n",
    "        features, prices, values = [], [], []\n",
    "        \n",
    "        date = df[\"date\"]\n",
    "        symbols = df[\"symbol\"]\n",
    "        date, symbols = list(set(date)), list(set(symbols))\n",
    "        for days in tqdm(date):\n",
    "            for symbol in symbols:\n",
    "                day = df[\"date\"] == days\n",
    "                sym = df[\"symbol\"] == symbol\n",
    "                day_data = df[day & sym]\n",
    "                news_num = len(day_data)\n",
    "                if news_num == 0: continue\n",
    "                feature = pd.concat([day_data[f\"f{idx+1:02d}\"] \n",
    "                                        for idx in range(16)], axis=1).to_numpy()\n",
    "                price = [day_data[f\"pre{idx}dreturn\"].to_numpy() for idx in range(2, -1, -1)]\n",
    "                price = np.concatenate([price], axis=0)[:,0]\n",
    "                value = day_data[\"nextreturn\"].to_numpy()[0]\n",
    "                if news_num > news_max:\n",
    "                    choice = np.random.choice(news_num, news_max, replace=False)\n",
    "                    feature, news_num = feature[choice], news_max\n",
    "                feature = np.pad(feature, [(0, news_max - news_num), (0, 0)])\n",
    "                features.append(feature)\n",
    "                prices.append(price)\n",
    "                values.append(value)\n",
    "                \n",
    "        self.len = len(features)\n",
    "        self.features, self.prices, self.values = features, prices, values\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.prices[idx], self.values[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 571/571 [00:09<00:00, 62.37it/s]\n"
     ]
    }
   ],
   "source": [
    "merge = pd.read_csv(\"../data/predict_dataset.csv\")\n",
    "dataset = Stock(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "validation_split = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "indices = {\n",
    "    \"train\" : indices[split:],\n",
    "    \"valid\" : indices[:split]\n",
    "}\n",
    "sampler = {x : SubsetRandomSampler(indices[x]) for x in [\"train\", \"valid\"]}\n",
    "loader = {x : DataLoader(dataset, batch_size=batch_size, sampler=sampler[x]) for x in [\"train\", \"valid\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 28\n"
     ]
    }
   ],
   "source": [
    "print(len(loader[\"train\"]), len(loader[\"valid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "for state in [\"train\", \"valid\"]:\n",
    "    for p in loader[state]:\n",
    "        continue\n",
    "print(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('IDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c5319918c1df56bbc8425fc11a4113500c53384b36f54418b1e7926749cda2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
