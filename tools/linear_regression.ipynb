{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                       \n",
    "import datetime as dt   \n",
    "import numpy as np                  \n",
    "import yfinance as yf                    \n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import mplfinance as mpf # pip install\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LinearRegression, ElasticNet\n",
    "from sklearn.svm import SVR                                                     # Integrate algorithms\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor # pip install\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_date = dt.date.today()                            # Take the actual date\n",
    "last_month_date = actual_date-dt.timedelta(days=600) \n",
    "actual_date = actual_date.strftime(\"%Y-%m-%d\") \n",
    "last_month_date = last_month_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "stock='AAPL'                                               # Stock name\n",
    "data = yf.download(stock, last_month_date, actual_date)  # Getting data from Yahoo Finance\n",
    "da= pd.DataFrame(data=data)\n",
    "da.to_csv('file.csv')\n",
    "df = pd.read_csv('./file.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['High', 'Low', 'Open', 'Volume']].values  # x features\n",
    "y = df['Close'].values   \n",
    "print(\"x=\")\n",
    "print(x)\n",
    "print(\"y=\")\n",
    "print(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=28) # Segment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((x_test[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()                                 # Standardize the data set\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)\n",
    "x_train[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the model name.\n",
    "names = ['LinerRegression',\n",
    "       'Ridge',\n",
    "       'Lasso',\n",
    "       'Random Forrest',\n",
    "       'Support Vector Regression',\n",
    "       'ElasticNet',\n",
    "       'XgBoost']\n",
    "\n",
    "#Define the model.\n",
    "# cv is the cross-validation idea here.\n",
    "models = [LinearRegression(),\n",
    "         RidgeCV(alphas=(0.001,0.1,1),cv=3),\n",
    "         LassoCV(alphas=(0.001,0.1,1),cv=5),\n",
    "         RandomForestRegressor(n_estimators=10),\n",
    "         SVR(),\n",
    "         ElasticNet(alpha=0.001,max_iter=10000),\n",
    "         XGBRegressor()]\n",
    "# Output the R2 scores of all regression models.\n",
    "\n",
    "#Define the R2 scoring function.\n",
    "def R2(model,x_train, x_test, y_train, y_test):\n",
    "        model_fitted = model.fit(x_train,y_train)\n",
    "        y_pred = model_fitted.predict(x_test)\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        return score\n",
    "%matplotlib inline\n",
    "#Traverse all models to score.\n",
    "x = []\n",
    "y = []\n",
    "for name,model in zip(names,models):\n",
    "        score = R2(model,x_train, x_test, y_train, y_test)\n",
    "        print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))\n",
    "        x.append(name)\n",
    "        y.append(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.ylim(0.95,1)\n",
    "plt.bar(x,y)\n",
    "plt.title(u\"Different linear regression R^2 scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model.\n",
    "'''\n",
    "  'kernel': kernel function\n",
    "  'C': SVR regularization factor\n",
    "  'gamma': 'rbf', 'poly' and 'sigmoid' kernel function coefficient, which affects the model performance\n",
    "'''\n",
    "parameters = {\n",
    "   'kernel': ['linear', 'rbf'],\n",
    "   'C': [0.1, 0.5,0.9,1,5],\n",
    "   'gamma': [0.001,0.01,0.1,1]\n",
    "}\n",
    "\n",
    "#Use grid search and perform cross validation.\n",
    "model = GridSearchCV(SVR(), param_grid=parameters, cv=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameter list: {'C': 5, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Optimal model: SVR(C=5, gamma=0.001, kernel='linear')\n",
      "Optimal R2 value: 0.9950849132689639\n"
     ]
    }
   ],
   "source": [
    "##Obtain optimal parameters.\n",
    "print(\"Optimal parameter list:\", model.best_params_)\n",
    "print(\"Optimal model:\", model.best_estimator_)\n",
    "print(\"Optimal R2 value:\", model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Perform visualization.\n",
    "ln_x_test = range(len(x_test))\n",
    "print(ln_x_test)\n",
    "y_predict = model.predict(x_test)\n",
    "#Set the canvas.\n",
    "plt.figure(figsize=(16,8))\n",
    "# plt.plot (ln_x_test, x_test[:,0], 'r-o', lw=2, label=u'High Price')\n",
    "# plt.plot (ln_x_test, x_test[:,1], 'g-o', lw=2, label=u'Low Price')\n",
    "#Draw with a red solid line.\n",
    "plt.plot (ln_x_test, y_test, 'r-o', lw=2, label=u'True values')\n",
    "#Draw with a green solid line.\n",
    "plt.plot (ln_x_test, y_predict, 'g--+', lw = 3, label=u'Predicted value with the SVR algorithm, $R^2$=%.3f' % (model.best_score_))\n",
    "#Display in a diagram.\n",
    "plt.legend(loc ='upper left')\n",
    "plt.grid(True)\n",
    "plt.title(u\"Stock price prediction with SVR\")\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot (ln_x_test, x_test[:,1], 'm-o', lw=2, label=u'True values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AAPL.csv')\n",
    "dates = list(range(0,int(len(df))))\n",
    "prices = df['Close']\n",
    "#Impute missing values (NaN)\n",
    "prices[np.isnan(prices)] = np.median(prices[~np.isnan(prices)])\n",
    "\n",
    "#Plot Original Data\n",
    "plt.plot(df['Close'], label='Close Price history')\n",
    "plt.title('Linear Regression | Time vs. Price (Original Data)')\n",
    "plt.legend()\n",
    "plt.xlabel('Date Integer')\n",
    "plt.show()\n",
    "\n",
    "#Convert to numpy array and reshape them\n",
    "dates = np.asanyarray(dates)\n",
    "prices = np.asanyarray(prices)\n",
    "dates = np.reshape(dates,(len(dates),1))\n",
    "prices = np.reshape(prices, (len(prices), 1))\n",
    "\n",
    "#Load Pickle File to get the previous saved model accuracy\n",
    "try:\n",
    "  pickle_in = open(\"prediction.pickle\", \"rb\")\n",
    "  reg = pickle.load(pickle_in)\n",
    "  xtrain, xtest, ytrain, ytest = train_test_split(dates, prices, test_size=0.2)\n",
    "  best = reg.score(ytrain, ytest)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "#Get the highest accuracy model\n",
    "best = 0\n",
    "for _ in range(100):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(dates, prices, test_size=0.2)\n",
    "    reg = LinearRegression().fit(xtrain, ytrain)\n",
    "    acc = reg.score(xtest, ytest)\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "        #Save model to pickle format\n",
    "        with open('prediction.pickle','wb') as f:\n",
    "            pickle.dump(reg, f)\n",
    "        print(acc)\n",
    "\n",
    "#Load linear regression model\n",
    "pickle_in = open(\"prediction.pickle\", \"rb\")\n",
    "reg = pickle.load(pickle_in)\n",
    "\n",
    "#Get the average accuracy of the model\n",
    "mean = 0\n",
    "for i in range(10):\n",
    "  #Random Split Data\n",
    "  msk = np.random.rand(len(df)) < 0.8\n",
    "  xtest = dates[~msk]\n",
    "  ytest = prices[~msk]\n",
    "  mean += reg.score(xtest,ytest)\n",
    "\n",
    "print(\"Average Accuracy:\", mean/10)\n",
    "\n",
    "#Plot Predicted VS Actual Data\n",
    "# plt.figure(figsize=(16,8))\n",
    "print(\"coef_:\", reg.coef_)\n",
    "print(\"intercept_:\", reg.intercept_)\n",
    "plt.plot(xtest, ytest, color='green',linewidth=1, label= 'Actual Price') #plotting the initial datapoints\n",
    "plt.plot(xtest, reg.predict(xtest), color='blue', linewidth=3, label = 'Predicted Price') #plotting the line made by linear regression\n",
    "plt.title('Linear Regression | Time vs. Price ')\n",
    "plt.legend()\n",
    "plt.xlabel('Date Integer')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "stock_data = yf.download('AAPL', start='2016-01-01', end='2021-10-01')\n",
    "stock_data.head()\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.title('Stock Prices History')\n",
    "plt.plot(stock_data['Close'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Prices ($)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_prices = stock_data['Close']\n",
    "values = close_prices.values\n",
    "training_data_len = math.ceil(len(values)* 0.8)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(values.reshape(-1,1))\n",
    "\n",
    "train_data = scaled_data[0: training_data_len, :]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scaled_data[training_data_len-60: , : ]\n",
    "x_test = []\n",
    "y_test = values[training_data_len:]\n",
    "\n",
    "for i in range(60, len(test_data)):\n",
    "  x_test.append(test_data[i-60:i, 0])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = nn.Sequential()\n",
    "model.add(layers.LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(layers.LSTM(100, return_sequences=False))\n",
    "model.add(layers.Dense(25))\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "#####################\n",
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2 \n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "    \n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "#####################\n",
    "num_epochs = 100\n",
    "hist = np.zeros(num_epochs)\n",
    "\n",
    "# Number of steps to unroll\n",
    "seq_dim =look_back-1  \n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    #model.hidden = model.init_hidden()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_train_pred = model(x_train)\n",
    "\n",
    "    loss = loss_fn(y_train_pred, y_train)\n",
    "    if t % 10 == 0 and t !=0:\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_test_pred = model(x_test)\n",
    "\n",
    "# invert predictions\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
    "y_train = scaler.inverse_transform(y_train.detach().numpy())\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(y_test.detach().numpy())\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "figure, axes = plt.subplots(figsize=(15, 6))\n",
    "axes.xaxis_date()\n",
    "\n",
    "axes.plot(df_ibm[len(df_ibm)-len(y_test):].index, y_test, color = 'red', label = 'Real IBM Stock Price')\n",
    "axes.plot(df_ibm[len(df_ibm)-len(y_test):].index, y_test_pred, color = 'blue', label = 'Predicted IBM Stock Price')\n",
    "#axes.xticks(np.arange(0,394,50))\n",
    "plt.title('IBM Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('IBM Stock Price')\n",
    "plt.legend()\n",
    "plt.savefig('ibm_pred.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stock_data.filter(['Close'])\n",
    "train = data[:training_data_len]\n",
    "validation = data[training_data_len:]\n",
    "validation['Predictions'] = predictions\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price USD ($)')\n",
    "plt.plot(train)\n",
    "plt.plot(validation[['Close', 'Predictions']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a7d309622ed6b71e556c1da103e1afe18816e801069c1ec6e69b2d440d1ea7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
