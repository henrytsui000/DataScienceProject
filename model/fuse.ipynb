{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henrytsui/anaconda3/envs/IDS/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_PATH = 'bert-base-uncased'\n",
    "MAX_LEN = 64\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained(BERT_PATH)\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock(Dataset):\n",
    "    def __init__(self, df) -> None:\n",
    "        self.pre = df[\"preprice\"]\n",
    "        self.post = df[\"latprice\"]\n",
    "        self.content = [tokenizer(text,padding='max_length', \n",
    "                       max_length = MAX_LEN, \n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\") for text in df[\"content\"]]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.post[idx] - self.pre[idx], self.content[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return merge.shape[0]\n",
    "\n",
    "merge = pd.read_csv(\"../data/merge.csv\", index_col=0)\n",
    "stock = Stock(merge)\n",
    "stock_loader = DataLoader(stock, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[  101, 10474,  2522,  1011,  3910,  2990, 27332, 14456,  2002,  3473,\n",
      "           2194,  1005,  2205,  3435,  1005,  2004, 14163,  6711,  3913, 27475,\n",
      "           2202,  3466,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0]],\n",
      "\n",
      "        [[  101,  1996,  2991,  1997,  2502,  6627,  2003, 12992,  2075,  4518,\n",
      "          24110,  3215,  2006,  2813,  2395,   102,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0]]]), 'token_type_ids': tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])}\n"
     ]
    }
   ],
   "source": [
    "num, con = next(iter(stock_loader))\n",
    "print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "print(con[\"attention_mask\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = bert.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
      "       device='cuda:0') tensor([[  101, 10474,  2522,  1011,  3910,  2990, 27332, 14456,  2002,  3473,\n",
      "          2194,  1005,  2205,  3435,  1005,  2004, 14163,  6711,  3913, 27475,\n",
      "          2202,  3466,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996,  2991,  1997,  2502,  6627,  2003, 12992,  2075,  4518,\n",
      "         24110,  3215,  2006,  2813,  2395,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "mask = con[\"attention_mask\"].to(DEVICE)\n",
    "text = con[\"input_ids\"].squeeze(1).to(DEVICE)\n",
    "print(mask, text)\n",
    "# bert(con[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bert(text, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.3090,  0.1375, -0.1950,  ..., -0.4220,  0.5317,  0.0663],\n",
      "         [ 1.0220, -0.0362, -0.0199,  ...,  0.2628,  0.8525, -0.2002],\n",
      "         [ 0.6710, -0.4314, -0.4480,  ..., -0.3828,  0.5428, -0.0963],\n",
      "         ...,\n",
      "         [ 0.2823,  0.0117, -0.1202,  ...,  0.1335,  0.2461, -0.0830],\n",
      "         [-0.2138, -0.3979, -0.3595,  ...,  0.3255,  0.4415, -0.2490],\n",
      "         [ 0.0946,  0.0277, -0.1058,  ...,  0.1156,  0.0821, -0.0057]],\n",
      "\n",
      "        [[-0.0510,  0.1963,  0.2168,  ..., -0.4943,  0.3540,  0.3200],\n",
      "         [-0.1961, -0.5545, -0.4311,  ..., -0.2283,  0.3729, -0.0934],\n",
      "         [-0.9456, -0.6790,  0.2886,  ..., -0.7133,  0.6041, -0.5557],\n",
      "         ...,\n",
      "         [ 0.1780, -0.2627,  0.3362,  ...,  0.0462,  0.2970,  0.1298],\n",
      "         [ 0.1960, -0.4050,  0.3419,  ..., -0.0775,  0.2562, -0.0417],\n",
      "         [ 0.1667, -0.2292,  0.4816,  ..., -0.1900,  0.0820, -0.0516]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8756, -0.4696, -0.8641,  ..., -0.2863, -0.5936,  0.7323],\n",
      "        [-0.8881, -0.4178, -0.6614,  ..., -0.1268, -0.6375,  0.8534]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4price(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_PATH)\n",
    "        self.fc = nn.Linear(768, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('IDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c5319918c1df56bbc8425fc11a4113500c53384b36f54418b1e7926749cda2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
