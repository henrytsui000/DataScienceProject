{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from tensorboardX import SummaryWriter\n",
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-n\", \"--name\", type=str, default=\"bert-base-uncased\", help=\"model name\")\n",
    "    parser.add_argument(\"-e\", \"--epochs\", type=int, default=50)\n",
    "    parser.add_argument(\"-b\", \"--batch-size\", type=int, default=128)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-5)\n",
    "    parser.add_argument(\"--max-len\", type=int, default=64)\n",
    "    parser.add_argument(\"-d\", \"--device\", type=str, default=\"cuda\")\n",
    "    parser.add_argument(\"--data\", type=str, default=\"../data/train_bert.csv\")\n",
    "    parser.add_argument(\"--weight\", type=str, default=\"../pretrained/bert_weight.pt\")\n",
    "\n",
    "    return parser\n",
    "\n",
    "args = make_parser().parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock(Dataset):\n",
    "    def __init__(self, df, model, max_len) -> None:\n",
    "        self.df = df\n",
    "        self.score = [float(score) for score in df[\"score\"]]\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model)\n",
    "        self.content = [self.tokenizer(text,padding='max_length', \n",
    "                       max_length = max_len, \n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\") for text in df[\"content\"]]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.score[idx], self.content[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "class Bert4price(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model)\n",
    "        self.ft_fc = nn.Sequential(\n",
    "            nn.Linear(768, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 16),\n",
    "        )\n",
    "        self.vl_fc = nn.Linear(16, 1)\n",
    "    def forward(self, text, mask):\n",
    "        _, output = self.bert(input_ids=text, attention_mask=mask,return_dict=False)\n",
    "        feature = self.ft_fc(output)\n",
    "        output = self.vl_fc(F.relu(feature))\n",
    "        return torch.squeeze(feature, 1).double(), torch.squeeze(output, 1).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bert4price(args.name)\n",
    "model = model.to(args.device)\n",
    "model.load_state_dict(torch.load(args.weight))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.read_csv(args.data, index_col=0)\n",
    "\n",
    "t0, t1, t2 = np.split(merge.sample(frac=1, random_state=42), [int(.8*merge.shape[0]), int(.9*merge.shape[0])])\n",
    "dataset = {x: Stock(s, args.name, args.max_len) for x, s in [(\"train\", t0), (\"valid\", t1), (\"test\", t2)]}\n",
    "loader = {x: DataLoader(dataset[x], batch_size=args.batch_size, num_workers=24, shuffle=True) \n",
    "                                            for x in [\"train\", \"valid\", \"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference():\n",
    "    res = dict()\n",
    "    for state in [\"train\", \"valid\", \"test\"]:\n",
    "        res[state] = {\"emb\" : [], \"ipt\" : [], \"opt\" : []}\n",
    "        emb_buf, ipt_buf, opt_buf = [], [], []\n",
    "        tqdm_bar = tqdm(loader[state], leave=False)\n",
    "        for value, content in tqdm_bar:\n",
    "            ipt_buf.append(value.numpy())\n",
    "            text, mask = content[\"input_ids\"].squeeze(1), content[\"attention_mask\"]\n",
    "            text, mask = text.to(args.device), mask.to(args.device)\n",
    "            value = value.to(args.device)\n",
    "        \n",
    "            emb, opt = model(text, mask)\n",
    "            emb = emb.cpu().detach().numpy()\n",
    "            opt = opt.cpu().detach().numpy()\n",
    "            emb_buf.append(emb)\n",
    "            opt_buf.append(opt)\n",
    "        res[state][\"emb\"] = np.concatenate(emb_buf)\n",
    "        res[state][\"ipt\"] = np.concatenate(ipt_buf)\n",
    "        res[state][\"opt\"] = np.concatenate(opt_buf)\n",
    "    return res\n",
    "res = inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in [\"train\", \"valid\", \"test\"]:\n",
    "    # print(state, F.mse_loss(res[state][\"ipt\"], res[state][\"opt\"]))\n",
    "    plot = sns.jointplot(x=\"ipt\", y=\"opt\", data = res[state])\n",
    "    plot.ax_marg_x.set_xlim(-30, 60)\n",
    "    plot.ax_marg_y.set_ylim(-30, 60)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(res[state][\"ipt\"], res[state][\"opt\"])\n",
    "print(fpr, tpr, threshold)\n",
    "\n",
    "auc1 = auc(fpr, tpr)\n",
    "## Plot the result\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc1)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('IDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c5319918c1df56bbc8425fc11a4113500c53384b36f54418b1e7926749cda2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
