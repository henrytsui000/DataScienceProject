{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henrytsui/anaconda3/envs/IDS/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "from tensorboardX import SummaryWriter\n",
    "from itertools import tee\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock(Dataset):\n",
    "    def __init__(self, df, news_max = 20) -> None:\n",
    "        features, prices, values = [], [], []\n",
    "        \n",
    "        date = df[\"date\"]\n",
    "        symbols = df[\"symbol\"]\n",
    "        date, symbols = list(set(date)), list(set(symbols))\n",
    "        for days in tqdm(date):\n",
    "            for symbol in symbols:\n",
    "                day = df[\"date\"] == days\n",
    "                sym = df[\"symbol\"] == symbol\n",
    "                day_data = df[day & sym]\n",
    "                news_num = len(day_data)\n",
    "                if news_num == 0: continue\n",
    "                feature = pd.concat([day_data[f\"f{idx+1:02d}\"] \n",
    "                                        for idx in range(16)], axis=1).to_numpy()\n",
    "                price = [day_data[f\"pre{idx}dreturn\"].to_numpy() for idx in range(2, -1, -1)]\n",
    "                price = np.concatenate([price], axis=0)[:,0]\n",
    "                value = day_data[\"nextreturn\"].to_numpy()[0]\n",
    "                if news_num > news_max:\n",
    "                    choice = np.random.choice(news_num, news_max, replace=False)\n",
    "                    feature, news_num = feature[choice], news_max\n",
    "                feature = np.pad(feature, [(0, news_max - news_num), (0, 0)])\n",
    "                features.append(feature)\n",
    "                prices.append(price)\n",
    "                values.append(value)\n",
    "                \n",
    "        self.len = len(features)\n",
    "        self.features, self.prices, self.values = features, prices, values\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.prices[idx], self.values[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-n\", \"--name\", type=str, default=\"bert-base-uncased\", help=\"model name\")\n",
    "    parser.add_argument(\"-e\", \"--epochs\", type=int, default=50)\n",
    "    parser.add_argument(\"-b\", \"--batch-size\", type=int, default=4096)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-5)\n",
    "    parser.add_argument(\"--max-len\", type=int, default=64)\n",
    "    parser.add_argument(\"-d\", \"--device\", type=str, default=\"cuda\")\n",
    "    parser.add_argument(\"--data\", type=str, default=\"./data/predict_dataset.csv\")\n",
    "    parser.add_argument(\"--bert-weight\", type=str, default=\"../pretrained/bert_weight.pt\")\n",
    "    parser.add_argument(\"--predict-weight\", type=str, default=\"../pretrained/predict.pt\")\n",
    "    parser.add_argument(\"--news-max\", type=int, default=20)\n",
    "\n",
    "    return parser\n",
    "args = make_parser().parse_args(\"\")\n",
    "pd.set_option('mode.chained_assignment', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_csv(\"../data/stock.csv\", index_col = 0)\n",
    "news = pd.read_csv(\"../data/predict_dataset.csv\")\n",
    "symbols = price.columns\n",
    "p2n = {\n",
    "    \"meta\" : \"META\",\n",
    "    \"goog\" : \"GOOGL\",\n",
    "    \"amzn\" : \"AMZN\",\n",
    "    \"nflx\" : \"NFLX\",\n",
    "    \"aapl\" : \"AAPL\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "def cal_ret(pre_day, cur_day):\n",
    "    return 100 * (cur_day - pre_day) / pre_day    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score2Predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_down = nn.Sequential(\n",
    "                                nn.Linear(320, 32),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(32, 3),\n",
    "                                nn.ReLU()\n",
    "                            )\n",
    "        self.predict = nn.Linear(6, 1)\n",
    "    def forward(self, news, price):\n",
    "        news = torch.flatten(news, start_dim=1).to(torch.float32)\n",
    "        price = torch.flatten(price, start_dim=1).to(torch.float32)\n",
    "        news = self.feature_down(news)\n",
    "        x = torch.cat((news, price), 1)\n",
    "        x = self.predict(x)\n",
    "        out = torch.flatten(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert2Score(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model)\n",
    "        self.ft_fc = nn.Sequential(\n",
    "                        nn.Linear(768, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, 16),\n",
    "                    )\n",
    "        self.vl_fc = nn.Linear(16, 1)\n",
    "    def forward(self, text, mask):\n",
    "        _, output = self.bert(input_ids=text, attention_mask=mask,return_dict=False)\n",
    "        feature = self.ft_fc(output)\n",
    "        output = self.vl_fc(F.relu(feature))\n",
    "        return torch.squeeze(feature, 1).double(), torch.squeeze(output, 1).double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args.name)\n",
    "bert = Bert2Score(args.name)\n",
    "predict = Score2Predict()\n",
    "bert.load_state_dict(torch.load(args.bert_weight))\n",
    "predict.load_state_dict(torch.load(args.predict_weight))\n",
    "bert = bert.to(args.device).eval()\n",
    "predict = predict.to(args.device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoPredict(prereturn, nowprice, news, tokenizer, bert, predict):\n",
    "    contents = [tokenizer(text,padding='max_length', \n",
    "                    max_length = args.max_len, \n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\") for text in news]\n",
    "    with torch.no_grad():\n",
    "        embs = []\n",
    "        for content in contents:\n",
    "            content = content.to(args.device)\n",
    "            text, mask = content[\"input_ids\"].squeeze(1), content[\"attention_mask\"]\n",
    "            text, mask = text.to(args.device), mask.to(args.device)\n",
    "            emb, _ = bert(text, mask)\n",
    "            embs.append(emb)\n",
    "        embs = torch.cat(embs)\n",
    "        embs = nn.ZeroPad2d((0, 0, args.news_max - embs.shape[0], 0))(embs)\n",
    "        prereturn = torch.tensor(prereturn)\n",
    "        prereturn = torch.unsqueeze(prereturn, 0).to(args.device)\n",
    "        embs = torch.unsqueeze(embs, 0).to(args.device)\n",
    "\n",
    "        ret = predict(embs, prereturn)\n",
    "        ret = ret.detach().cpu().numpy()\n",
    "        return (ret[0]/100+1)*nowprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in symbols: price[symbol+\"_pred\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517/517 [03:21<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for didx, date in enumerate(tqdm(price.index)):\n",
    "    for p_symbol in symbols:\n",
    "        symbol = p2n[p_symbol]\n",
    "        day = news[\"date\"] == date\n",
    "        sym = news[\"symbol\"] == symbol\n",
    "        day_data = news[day & sym]\n",
    "        if not len(day_data): continue\n",
    "        # print(\"ZERO\", date, symbol)\n",
    "        preprice = [price[p_symbol].iloc[didx + pidx] for pidx in range(-3, 1, 1)]\n",
    "        prereturn = [cal_ret(pred, d) for pred, d in pairwise(preprice)]\n",
    "        nowprice = price[p_symbol].iloc[didx]\n",
    "        new = list(day_data[\"content\"])\n",
    "        random.shuffle(new)\n",
    "        nprice = GoPredict(prereturn, nowprice, new[:20], tokenizer, bert, predict)\n",
    "        # print(nprice)\n",
    "        price[p_symbol+\"_pred\"].iloc[didx+1] = nprice.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.to_csv(\"../data/predict_value.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('IDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c5319918c1df56bbc8425fc11a4113500c53384b36f54418b1e7926749cda2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
