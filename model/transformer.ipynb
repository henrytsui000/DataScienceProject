{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucytuan/anaconda3/envs/IDS/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pd.read_csv(\"../data/tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "batchsize = 250\n",
    "lr = 1e-4\n",
    "numworker =24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predict(nn.Module):\n",
    "    def __init__(self, infeature, outfeature):\n",
    "        super().__init__()\n",
    "        self.transform = nn.Linear(infeature, outfeature)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.transform(x)\n",
    "        out = self.leakyrelu(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = predict(163, 1)\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_feature:\n",
    "\"\"\"\n",
    "day 1 : 16*1 + 16*1 + ... = 160*1\n",
    "day 2 : 16*1 + 16*1 + ... = 160*1\n",
    ".\n",
    ".\n",
    ".\n",
    "day 6643 : 16*1 + 16*1 + ... = 160*1\n",
    "\n",
    "\"\"\"\n",
    "# price_return:\n",
    "\"\"\"\n",
    "day 1 : 1*1 + 1*1 + 1*1 = 3*1\n",
    "day 2 : 1*1 + 1*1 + 1*1 = 3*1\n",
    ".\n",
    ".\n",
    ".\n",
    "day 6643 : 1*1 + 1*1 + 1*1 = 3*1\n",
    "\"\"\"\n",
    "# ground_truth:\n",
    "\"\"\"\n",
    "day 1 : 1*1\n",
    "day 2 : 1*1\n",
    ".\n",
    ".\n",
    ".\n",
    "day 6643 : 1*1\n",
    "\"\"\"\n",
    "news_feature = np.random.randn(6643, 160)\n",
    "price_return = np.random.randn(6643,3)\n",
    "ground_truth = np.random.randn(6643,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/new_pred.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = df[df[\"symbol\"]==\"META\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       -1.918452\n",
      "1       -1.622287\n",
      "2       -1.872377\n",
      "3       -1.693291\n",
      "4       -1.694585\n",
      "           ...   \n",
      "16021   -1.674121\n",
      "16107   -1.683615\n",
      "16306   -1.739593\n",
      "16307   -1.689846\n",
      "16308   -1.734896\n",
      "Name: f01, Length: 1484, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "hi = meta[\"f01\"]\n",
    "print(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'f01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/IDS/lib/python3.8/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/IDS/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/IDS/lib/python3.8/site-packages/pandas/_libs/index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'f01'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# news_feature = news_feature.lstrip('0')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m10\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     meta \u001b[39m=\u001b[39m meta[\u001b[39m\"\u001b[39;49m\u001b[39mf01\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      4\u001b[0m \u001b[39m# for i in range(1,10):\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#     meta = meta[f\"f0{i}\"]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(meta)\n",
      "File \u001b[0;32m~/anaconda3/envs/IDS/lib/python3.8/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/IDS/lib/python3.8/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/anaconda3/envs/IDS/lib/python3.8/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'f01'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      symbol            datentime  \\\n",
      "0       META  2022-11-05 23:13:24   \n",
      "1       META  2022-11-05 21:02:00   \n",
      "2       META  2022-11-05 21:00:00   \n",
      "3       META  2022-11-05 19:49:01   \n",
      "4       META  2022-11-05 14:58:00   \n",
      "...      ...                  ...   \n",
      "25273   NFLX  2021-01-22 17:55:08   \n",
      "25274   NFLX  2021-01-22 17:48:47   \n",
      "25275   NFLX  2021-01-22 17:42:59   \n",
      "25276   NFLX  2021-01-22 16:55:04   \n",
      "25277   NFLX  2021-01-22 16:30:00   \n",
      "\n",
      "                                                 content      match  \\\n",
      "0      Twitter co-founder Jack Dorsey admits he grew ...  13.746987   \n",
      "1      The Fall of Big Tech Is Boosting Stock Quants ...   9.408848   \n",
      "2      Meta Stock: Mr. Market Shorted Zuckerberg; Fut...  13.847881   \n",
      "3      What stock investors should watch for in the m...  11.597897   \n",
      "4                    Meta Lesson 1: Corporate Governance   3.993389   \n",
      "...                                                  ...        ...   \n",
      "25273  UBS Upgrades Disney On Streaming Strength, Val...  50.651016   \n",
      "25274  This New Action Film Directed By RZA Is Now Th...  17.759022   \n",
      "25275  IBM, Intel Pressure Stocks Along With Worry Ab...  17.065092   \n",
      "25276  Did You Miss This Valuable Info in Netflix's L...  18.219120   \n",
      "25277  Netflix Beat Subscriber Expectations by Return...  18.618023   \n",
      "\n",
      "       sentiment      score  preprice  nowprice  nextprice       f01  ...  \\\n",
      "0      -0.458800  -6.307118     90.79     96.72      96.47 -1.918452  ...   \n",
      "1       0.624900   5.879589     90.79     96.72      96.47 -1.622287  ...   \n",
      "2      -0.571900  -7.919603     90.79     96.72      96.47 -1.872377  ...   \n",
      "3       0.000000   0.000000     90.79     96.72      96.47 -1.693291  ...   \n",
      "4       0.510600   2.039024     90.79     96.72      96.47 -1.694585  ...   \n",
      "...          ...        ...       ...       ...        ...       ...  ...   \n",
      "25273   0.691150  35.007450    579.84    565.17     556.78 -2.026150  ...   \n",
      "25274  -0.084250  -1.496198    579.84    565.17     556.78 -1.581046  ...   \n",
      "25275   0.435667   7.434697    579.84    565.17     556.78 -1.572732  ...   \n",
      "25276   0.669900  12.204988    579.84    565.17     556.78 -1.512792  ...   \n",
      "25277   0.165490   3.081097    579.84    565.17     556.78 -1.693078  ...   \n",
      "\n",
      "            f07        f08        f09        f10       f11       f12  \\\n",
      "0     -0.840308  20.511791  -0.424341  -0.037723 -0.158139 -0.292643   \n",
      "1     -1.997512   7.145590   4.415199   5.293066 -0.693726 -1.301412   \n",
      "2     -0.776553  19.439938  -0.409220  -0.041686 -0.145274 -0.259019   \n",
      "3     -1.414491   9.724914   2.652583   3.168805 -0.477094 -0.778998   \n",
      "4     -1.528956   9.230800   2.955172   3.531279 -0.503951 -0.857621   \n",
      "...         ...        ...        ...        ...       ...       ...   \n",
      "25273 -6.488031  -0.160149  18.433956  23.083088 -2.772384 -5.824766   \n",
      "25274 -2.332398   6.025882   5.421753   6.512555 -0.799054 -1.616427   \n",
      "25275 -2.225223   6.095010   5.137889   6.131938 -0.767924 -1.508086   \n",
      "25276 -2.687539   4.256444   6.680932   8.045105 -0.947063 -2.028650   \n",
      "25277 -1.560973   9.051538   3.116481   3.725386 -0.536032 -0.911453   \n",
      "\n",
      "             f13       f14        f15        f16  \n",
      "0      -4.731168 -0.093516   0.129046  -0.059702  \n",
      "1       5.913006 -1.775603   8.082360   5.380587  \n",
      "2      -4.436836 -0.106407   0.169776  -0.051664  \n",
      "3       2.621681 -1.406020   5.344369   3.504629  \n",
      "4       3.183484 -1.479707   5.784324   3.823542  \n",
      "...          ...       ...        ...        ...  \n",
      "25273  29.196268 -5.998186  31.952442  22.155663  \n",
      "25274   7.736181 -1.986986   9.688302   6.489141  \n",
      "25275   7.233639 -1.911884   9.198209   6.137291  \n",
      "25276  10.103474 -2.327293  11.726243   7.936880  \n",
      "25277   3.476539 -1.511455   6.049640   3.990074  \n",
      "\n",
      "[25278 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "class Stock(Dataset):\n",
    "    def __init__(self, news_feature, model, max_len) -> None:\n",
    "        self.df = news_feature\n",
    "        self.news = [float(score) for score in df[\"score\"]]\n",
    "        self.price = [self.tokenizer(text,padding='max_length', \n",
    "                       max_length = max_len, \n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\") for text in df[\"content\"]]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.score[idx], self.content[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [91], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# input dim : news_feature 160*1 + price_return_3_days 3*1 + ans 1*1 = 164*1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# ground_truth : price_return_next_day\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m news_feature \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(news_feature)  \u001b[39m# 16*10\u001b[39;00m\n\u001b[1;32m      4\u001b[0m price_return \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(price_return)\n\u001b[1;32m      5\u001b[0m ground_truth \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(ground_truth)\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "# input dim : news_feature 160*1 + price_return_3_days 3*1 + ans 1*1 = 164*1\n",
    "# ground_truth : price_return_next_day\n",
    "news_feature = torch.tensor(news_feature)  # 16*10\n",
    "price_return = torch.tensor(price_return)\n",
    "ground_truth = torch.tensor(ground_truth)\n",
    "# 80, 10, 10\n",
    "lenn = len(news_feature)\n",
    "lenp = len(price_return)\n",
    "leng = len(ground_truth)\n",
    "train_loader = torch.cat((news_feature[0:int(lenn*0.8),:], price_return[0:int(lenp*0.8),:], ground_truth[0:int(leng*0.8),:]),1)\n",
    "valid_loader = torch.cat((news_feature[int(lenn*0.8):int(lenn*0.9),:], price_return[int(lenp*0.8):int(lenp*0.9),:], ground_truth[int(leng*0.8):int(leng*0.9),:]),1)\n",
    "test_loader = torch.cat((news_feature[int(lenn*0.9):,:], price_return[int(lenp*0.9):,:], ground_truth[int(leng*0.9):,:]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(mymodel.parameters(), lr=0.1, momentum=0.9)\n",
    "lr_schedule = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (1790028893.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [36], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "min_loss = 1e4\n",
    "\n",
    "for eps in range(epoch):\n",
    "    mymodel.train()\n",
    "    loss_list = []\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = mymodel.forward(data[:len(data)-1])\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        loss = loss(out,data[len(data)-1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_schedule.step()\n",
    "        loss_list = loss_list.append(loss)\n",
    "    train_loss = np.mean(loss_list)\n",
    "    mymodel.eval()\n",
    "    valid_loss_list = []\n",
    "    for news, price, ans in valid_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = mymodel.forward(news, price)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        loss = loss(out,ans)\n",
    "        if min_loss > loss:\n",
    "            min_loss = loss\n",
    "            torch.save(mymodel.state_dict(), f\"./ckpt/mymodel.pt\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_schedule.step()\n",
    "        valid_loss_list = valid_loss_list.append(loss)\n",
    "    valid_loss = np.mean(valid_loss_list)\n",
    "    print(f\"epoch:{eps}, train loss: {train_loss}, valid loss: {valid_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "mymodel.load_state_dict(torch.load(f\"./ckpt/mymodel.pt\"))\n",
    "mymodel.eval()\n",
    "for eps in range(epoch):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for news, price, ans in iter(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = mymodel.forward(news, price)\n",
    "        loss = nn.CrossEntropyLoss(out, ans)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_schedule.step()\n",
    "        loss_list = loss_list.append(loss)\n",
    "    test_loss = np.mean(loss_list)\n",
    "print(f\"test_loss:{test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = cat[cat[\"symbol\"]==\"AAPL\"] \n",
    "print(len(aapl)) #6643\n",
    "print(aapl)\n",
    "amzn = cat[cat[\"symbol\"]==\"AMZN\"] \n",
    "print(len(amzn)) #7482\n",
    "print(amzn)\n",
    "nflx = cat[cat[\"symbol\"]==\"NFLX\"] \n",
    "print(len(nflx)) # 5358\n",
    "print(nflx)\n",
    "googl = cat[cat[\"symbol\"]==\"GOOGL\"] \n",
    "print(len(googl))  #4311\n",
    "print(googl)\n",
    "meta = cat[cat[\"symbol\"]==\"META\"] \n",
    "print(len(meta))   # 1484\n",
    "print(meta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72b71fc53b4852de6adbc5d800e915723fe7a4acd43f1cc6118b311d0327eb76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
